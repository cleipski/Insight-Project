{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database set-up\n",
    "\n",
    "1. take the '\\*.json' files from the Flickr API query and put them in a PostgreSQL database. \n",
    "\n",
    "2. clean the database for duplicates from the image search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command-line \n",
    "\n",
    "On the 'psql' command line, certain queries can be run:\n",
    "\n",
    "* '\\l' to list all databases the server is connected to\n",
    "* '\\c db_name' to connect to database with name 'db_name'\n",
    "* '\\dt+' to see tables within the database\n",
    "* '\\d table_name' to see details (e.g., schema) of table 'table_name'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "\n",
    "## Python packages - you may have to pip install sqlalchemy, sqlalchemy_utils, and psycopg2.\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open connection to server and create database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In Python: Define a database name (we're using a dataset on births, so I call it \n",
    "# birth_db), and your username and password used above. \n",
    "dbname = 'flickr_db'\n",
    "#username = 'username'\n",
    "#pswd = 'password'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## 'engine' is a connection to a database\n",
    "## Here, we're using postgres, but sqlalchemy can connect to other things too.\n",
    "#engine = create_engine('postgresql://%s:%s@localhost/%s'%(username,pswd,dbname))\n",
    "engine = create_engine('postgresql://@localhost/%s'%(dbname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://@localhost/flickr_db\n"
     ]
    }
   ],
   "source": [
    "print(engine.url)\n",
    "# Replace localhost with IP address if accessing a remote server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "## create a database (if it doesn't exist)\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "print(database_exists(engine.url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to an existing database\n",
    "conn = psycopg2.connect(\"dbname=flickr_db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open a cursor to perform database operations\n",
    "cur = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare schema and create empty table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'geo_is_public': 1, u'place_id': u'Fcg9CH9TVrIdknMo', u'owner': u'53487315@N00', u'id': u'435803691', u'title': u'flowers at Chateau St. Jean', u'woeid': u'2486809', u'geo_is_friend': 0, u'geo_is_contact': 0, u'datetaken': u'2004-05-30 17:49:42', u'farm': 1, u'secret': u'0f57b1452d', u'latitude': u'38.427924', u'accuracy': u'16', u'isfamily': 0, u'ispublic': 1, u'tags': u'california flower gardens wine sonoma chateaustjean flowersfoliage pss:opd=1085935782', u'isfriend': 0, u'geo_is_family': 0, u'dateupload': u'1085935782', u'width_m': u'500', u'datetakenunknown': 0, u'datetakengranularity': u'0', u'longitude': u'-122.547935', u'server': u'176', u'url_m': u'https://farm1.staticflickr.com/176/435803691_0f57b1452d.jpg', u'context': 0, u'height_m': u'333'}\n"
     ]
    }
   ],
   "source": [
    "# Get schema for db from query response\n",
    "in_folder = os.path.join('..','..','data','photo_search','Napa')\n",
    "files = glob.glob(os.path.join(in_folder,'*.json'))\n",
    "total_all_id = []\n",
    "for idx,tmp_file in enumerate(files):\n",
    "    with open(tmp_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    n_total = int(data['photos']['total'])\n",
    "    if n_total == 0:\n",
    "        pass\n",
    "    else:\n",
    "        photo = data['photos']['photo'][0]\n",
    "        print(photo)\n",
    "        flickr_keys = photo.keys()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geo_is_public\n",
      "place_id\n",
      "owner\n",
      "id\n",
      "title\n",
      "woeid\n",
      "geo_is_friend\n",
      "geo_is_contact\n",
      "datetaken\n",
      "farm\n",
      "secret\n",
      "latitude\n",
      "accuracy\n",
      "isfamily\n",
      "ispublic\n",
      "tags\n",
      "isfriend\n",
      "geo_is_family\n",
      "dateupload\n",
      "width_m\n",
      "datetakenunknown\n",
      "datetakengranularity\n",
      "longitude\n",
      "server\n",
      "url_m\n",
      "context\n",
      "height_m\n"
     ]
    }
   ],
   "source": [
    "# Show keys\n",
    "for flickr_key in flickr_keys:\n",
    "    print(flickr_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'geo_is_public': '', 'place_id': '', 'owner': '', 'id': '', 'title': '', 'woeid': '', 'geo_is_friend': '', 'geo_is_contact': '', 'datetaken': '', 'isfriend': '', 'secret': '', 'latitude': '', 'accuracy': '', 'isfamily': '', 'ispublic': '', 'tags': '', 'farm': '', 'geo_is_family': '', 'dateupload': '', 'width_m': '', 'datetakenunknown': '', 'datetakengranularity': '', 'longitude': '', 'server': '', 'url_m': '', 'context': '', 'height_m': ''}\n"
     ]
    }
   ],
   "source": [
    "# Turn into dictionary with 'flickr_key' being the key and POSTGRES column type the value.\n",
    "postgre_schema = {str(tmp_key): '' for tmp_key in flickr_keys}\n",
    "print(postgre_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hardcode format\n",
    "# check here for varchar vs text\n",
    "# http://stackoverflow.com/questions/4848964/postgresql-difference-between-text-and-varchar-character-varying\n",
    "\n",
    "format_dict = {\n",
    "    'geo_is_public': 'integer' , \n",
    "    'place_id': 'text',\n",
    "    'owner': 'text',\n",
    "    'id': 'bigint',\n",
    "    'title': 'text',\n",
    "    'woeid': 'integer',\n",
    "    'geo_is_friend': 'integer',\n",
    "    'geo_is_contact': 'integer',\n",
    "    'datetaken': 'timestamp',\n",
    "    'farm': 'integer',\n",
    "    'secret': 'text',\n",
    "    'latitude': 'double precision',\n",
    "    'accuracy': 'integer',\n",
    "    'isfamily': 'integer',\n",
    "    'ispublic': 'integer',\n",
    "    'tags': 'text',\n",
    "    'isfriend': 'integer',\n",
    "    'geo_is_family': 'integer',\n",
    "    'dateupload': 'integer',\n",
    "    'width_m': 'integer',\n",
    "    'datetakenunknown': 'integer',\n",
    "    'datetakengranularity': 'integer',\n",
    "    'longitude': 'double precision',\n",
    "    'server': 'integer',\n",
    "    'url_m': 'text',\n",
    "    'context': 'integer',\n",
    "    'height_m': 'integer'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'geo_is_public': 'integer', 'place_id': 'text', 'owner': 'text', 'id': 'bigint', 'title': 'text', 'woeid': 'integer', 'geo_is_friend': 'integer', 'geo_is_contact': 'integer', 'datetaken': 'timestamp', 'isfriend': 'integer', 'secret': 'text', 'latitude': 'double precision', 'accuracy': 'integer', 'isfamily': 'integer', 'ispublic': 'integer', 'tags': 'text', 'farm': 'integer', 'geo_is_family': 'integer', 'dateupload': 'integer', 'width_m': 'integer', 'datetakenunknown': 'integer', 'datetakengranularity': 'integer', 'longitude': 'double precision', 'server': 'integer', 'url_m': 'text', 'context': 'integer', 'height_m': 'integer'}\n"
     ]
    }
   ],
   "source": [
    "# Merge postgres schema with format dict\n",
    "for tmp_key in postgre_schema.keys():\n",
    "    tmp_format = format_dict[tmp_key]\n",
    "    postgre_schema[tmp_key] = tmp_format\n",
    "print(postgre_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add 'county' and Primary key\n",
    "postgre_schema['county'] = 'text'\n",
    "postgre_schema['title_tags'] = 'text'\n",
    "postgre_schema['pk'] = 'serial PRIMARY KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All is well!\n"
     ]
    }
   ],
   "source": [
    "# Turn into ordered list with fixed length columns first, leading with primary key\n",
    "# http://stackoverflow.com/questions/12604744/does-the-order-of-columns-in-a-postgres-table-impact-performance\n",
    "postgre_schema_list = []\n",
    "# Primary key first\n",
    "postgre_schema_list += ([(k, postgre_schema[k]) \n",
    "                         for k in postgre_schema.keys() if k == 'pk'])\n",
    "postgre_schema_list += ([(k, postgre_schema[k]) \n",
    "                         for k in postgre_schema.keys() if postgre_schema[k] == 'integer'])\n",
    "postgre_schema_list += ([(k, postgre_schema[k]) \n",
    "                         for k in postgre_schema.keys() if postgre_schema[k] == 'bigint'])\n",
    "postgre_schema_list += ([(k, postgre_schema[k]) \n",
    "                         for k in postgre_schema.keys() if postgre_schema[k] == 'double precision'])\n",
    "postgre_schema_list += ([(k, postgre_schema[k]) \n",
    "                         for k in postgre_schema.keys() if postgre_schema[k] == 'timestamp'])\n",
    "postgre_schema_list += ([(k, postgre_schema[k]) \n",
    "                         for k in postgre_schema.keys() if postgre_schema[k] == 'text'])\n",
    "# Check that everything is still there\n",
    "if len(postgre_schema_list) == len(postgre_schema.keys()):\n",
    "    print('All is well!')\n",
    "else:\n",
    "    print('You forgot something!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('pk', 'serial PRIMARY KEY'), ('geo_is_public', 'integer'), ('woeid', 'integer'), ('geo_is_friend', 'integer'), ('geo_is_contact', 'integer'), ('isfriend', 'integer'), ('accuracy', 'integer'), ('isfamily', 'integer'), ('ispublic', 'integer'), ('farm', 'integer'), ('geo_is_family', 'integer'), ('dateupload', 'integer'), ('width_m', 'integer'), ('datetakenunknown', 'integer'), ('datetakengranularity', 'integer'), ('server', 'integer'), ('context', 'integer'), ('height_m', 'integer'), ('id', 'bigint'), ('latitude', 'double precision'), ('longitude', 'double precision'), ('datetaken', 'timestamp'), ('title_tags', 'text'), ('place_id', 'text'), ('county', 'text'), ('owner', 'text'), ('title', 'text'), ('secret', 'text'), ('tags', 'text'), ('url_m', 'text')]\n"
     ]
    }
   ],
   "source": [
    "print(postgre_schema_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE flickr_all (pk serial PRIMARY KEY, geo_is_public integer, woeid integer, geo_is_friend integer, geo_is_contact integer, isfriend integer, accuracy integer, isfamily integer, ispublic integer, farm integer, geo_is_family integer, dateupload integer, width_m integer, datetakenunknown integer, datetakengranularity integer, server integer, context integer, height_m integer, id bigint, latitude double precision, longitude double precision, datetaken timestamp, title_tags text, place_id text, county text, owner text, title text, secret text, tags text, url_m text);\n"
     ]
    }
   ],
   "source": [
    "# Build 'CREATE TABLE; string\n",
    "tmp_str = ''\n",
    "for idx, column in enumerate(postgre_schema_list):\n",
    "    tmp_str = tmp_str+column[0]+' '+column[1]\n",
    "    if idx < len(postgre_schema_list)-1:\n",
    "        tmp_str = tmp_str+', '\n",
    "str_create_table = \"CREATE TABLE flickr_all (\"+tmp_str+\");\"\n",
    "print(str_create_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Execute a command: this creates a new table\n",
    "cur.execute(str_create_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make the changes to the database persistent\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write data to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create 'INSERT' string\n",
    "def create_insert_string_from_dict(indict,county):\n",
    "    \"\"\"\n",
    "    From input dictionary extract key, value pairs \n",
    "    and build separate strings for SQL 'INSERT'. \n",
    "    Watch out for order in schema.\n",
    "    \"\"\"\n",
    "    # Rearrange key/values pairs according to 'postgre_schema_list'\n",
    "    keys_str = ''\n",
    "    values_str = ''\n",
    "    for idx,psl in enumerate(postgre_schema_list):\n",
    "        if psl[0] == 'pk':\n",
    "            pass\n",
    "        elif psl[0] == 'county':\n",
    "            keys_str += psl[0]+\",\"\n",
    "            values_str += \"'\"+county+\"',\"\n",
    "        elif psl[1] == 'timestamp':\n",
    "            keys_str += psl[0]+\",\"\n",
    "            time_str = str(indict[psl[0]])\n",
    "            if '0000' in time_str:\n",
    "                #print(time_str)\n",
    "                time_str = '1800-01-01 00:00:00'\n",
    "            values_str += \"TIMESTAMP '\"+time_str+\"',\"\n",
    "        elif psl[0] not in indict.keys():\n",
    "            pass\n",
    "        else:\n",
    "            keys_str += psl[0]+\",\"\n",
    "            try:\n",
    "                tmp_str = str(indict[psl[0]])\n",
    "            except UnicodeEncodeError:\n",
    "                tmp_str = indict[psl[0]].encode(errors='ignore')\n",
    "            if \"'\" in tmp_str:\n",
    "                tmp_str = tmp_str.replace(\"'\",\"\")\n",
    "            values_str += \"'\"+tmp_str+\"',\"\n",
    "    # Build combined 'title_tags' field\n",
    "    tmp_keys = keys_str.split(',')\n",
    "    tmp_values = values_str.split(',') \n",
    "    tmp_title_idx = [idx for idx,x in enumerate(tmp_keys) if x == 'title'][0]\n",
    "    tmp_tags_idx = [idx for idx,x in enumerate(tmp_keys) if x == 'tags'][0]\n",
    "    tmp_title = tmp_values[tmp_title_idx][:-1]\n",
    "    tmp_tags = tmp_values[tmp_tags_idx][1:]\n",
    "    keys_str += 'title_tags'+\",\"\n",
    "    tmp_title_tags = ' '.join([tmp_title,tmp_tags]).lower()\n",
    "    tmp_title_tags = \"'\"+tmp_title_tags.replace(\"'\",\"\")+\"',\"\n",
    "    values_str += tmp_title_tags\n",
    "    # remove trailing comma\n",
    "    keys_str = keys_str[:-1]\n",
    "    values_str = values_str[:-1]\n",
    "    # return strings\n",
    "    return keys_str, values_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alameda\n",
      "--- 314.083680153 seconds ---\n",
      "Contra Costa\n",
      "--- 844.815540075 seconds ---\n",
      "Marin\n",
      "--- 143.336902142 seconds ---\n",
      "Napa\n",
      "--- 42.4450309277 seconds ---\n",
      "San Francisco\n",
      "--- 950.191221952 seconds ---\n",
      "San Mateo\n",
      "--- 222.037982941 seconds ---\n",
      "Santa Clara\n",
      "--- 344.044910908 seconds ---\n",
      "Santa Cruz\n",
      "--- 105.748348951 seconds ---\n",
      "Solano\n",
      "--- 37.4602270126 seconds ---\n",
      "Sonoma\n",
      "--- 87.890130043 seconds ---\n",
      "--- 3092.05579114 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time_overall = time.time()\n",
    "# Now that I know how to inject data, let's do the same for all other counties\n",
    "counties = ['Alameda','Contra Costa','Marin','Napa','San Francisco',\n",
    "            'San Mateo','Santa Clara','Santa Cruz','Solano','Sonoma']\n",
    "# But to be conservative, let's do it one county at a time\n",
    "fail_list = []\n",
    "error_list = []\n",
    "for county in counties:\n",
    "    print(county)\n",
    "    start_time = time.time()\n",
    "    in_folder = os.path.join('..','..','data','photo_search',county)\n",
    "    files = glob.glob(os.path.join(in_folder,'*.json'))\n",
    "#     do_print = True\n",
    "    for idx,tmp_file in enumerate(files):\n",
    "        with open(tmp_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        n_total = data['photos']['total']\n",
    "        if n_total == 0:\n",
    "            pass\n",
    "        else:\n",
    "            for photo in data['photos']['photo']:\n",
    "                keys_str, values_str = create_insert_string_from_dict(photo,county)\n",
    "                insert_str = \"INSERT INTO flickr_all (\"+keys_str+\") VALUES (\"+values_str+\");\"\n",
    "#                 if do_print:\n",
    "#                     print(insert_str)\n",
    "#                     do_print = False\n",
    "                cur.execute(insert_str)\n",
    "    # Make the changes to the database persistent\n",
    "    conn.commit()\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "                \n",
    "print(\"Total\")                \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time_overall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commiting all json to SQL: timestamps\n",
    "\n",
    "Alameda<br/>\n",
    "--- 314.083680153 seconds ---<br/>\n",
    "Contra Costa<br/>\n",
    "--- 844.815540075 seconds ---<br/>\n",
    "Marin<br/>\n",
    "--- 143.336902142 seconds ---<br/>\n",
    "Napa<br/>\n",
    "--- 42.4450309277 seconds ---<br/>\n",
    "San Francisco<br/>\n",
    "--- 950.191221952 seconds ---<br/>\n",
    "San Mateo<br/>\n",
    "--- 222.037982941 seconds ---<br/>\n",
    "Santa Clara<br/>\n",
    "--- 344.044910908 seconds ---<br/>\n",
    "Santa Cruz<br/>\n",
    "--- 105.748348951 seconds ---<br/>\n",
    "Solano<br/>\n",
    "--- 37.4602270126 seconds ---<br/>\n",
    "Sonoma<br/>\n",
    "--- 87.890130043 seconds ---<br/>\n",
    "Total<br/>\n",
    "--- 3092.05579114 seconds ---<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Inspect fail files and error messages\n",
    "print(len(fail_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make the changes to the database persistent\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rollback transaction that created errors\n",
    "conn.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "* Alameda: 22 entries had 'date_taken' of '0000-01-01 00:00:00' or even '0000-00-00 00:00:00', which produced an error from the database because it could not be converted to a datetime object. I changed it to '1800-01-01 00:00:00' while creating the INSERT string to avoid this error.\n",
    "\n",
    "* Contra Costa: Same issue as above for 95 entries. \n",
    "\n",
    "* Marin: 4 issues with 'date_taken' (as above)\n",
    "\n",
    "* San Francisco: 1040 date errors\n",
    "\n",
    "* San Mateo: 13 date errors\n",
    "\n",
    "* Santa Clara: 16 date errors\n",
    "\n",
    "* Santa Cruz: 5 date errors\n",
    "\n",
    "* Solano: No INSERT errors\n",
    "\n",
    "* Sonoma: No INSERT errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean table: remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 229.358649015 seconds ---\n",
      "(8425185, 8)\n"
     ]
    }
   ],
   "source": [
    "# Check content before clean\n",
    "start_time = time.time()\n",
    "# set query string\n",
    "sql_query = \"\"\"\n",
    "SELECT \n",
    "    id,longitude,latitude,title,tags,dateupload,datetaken,title_tags\n",
    "FROM \n",
    "    flickr_all; \n",
    "\"\"\"\n",
    "# Run query and save in DF\n",
    "flickr_from_sql = pd.read_sql_query(sql_query,conn)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(flickr_from_sql.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean duplicates\n",
    "# https://wiki.postgresql.org/wiki/Deleting_duplicates\n",
    "sql_string = \"\"\"\n",
    "DELETE FROM flickr_all\n",
    "WHERE pk IN (SELECT pk\n",
    "              FROM (SELECT pk,\n",
    "                             ROW_NUMBER() OVER (partition BY id ORDER BY pk) AS rnum\n",
    "                     FROM flickr_all) t\n",
    "              WHERE t.rnum > 1);\n",
    "\"\"\"\n",
    "cur.execute(sql_string)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 100.91078496 seconds ---\n",
      "(4915904, 8)\n"
     ]
    }
   ],
   "source": [
    "# Check content after clean\n",
    "start_time = time.time()\n",
    "# set query string\n",
    "sql_query = \"\"\"\n",
    "SELECT \n",
    "    id,longitude,latitude,title,tags,dateupload,datetaken,title_tags\n",
    "FROM \n",
    "    flickr_all;\n",
    "\"\"\"\n",
    "# Run query and save in DF\n",
    "flickr_from_sql_clean = pd.read_sql_query(sql_query,conn)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(flickr_from_sql_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size of SQL table has been reduced from 8,425,185 entries to 4,915,904 entries when dropping duplicates as identified by image id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the fastest way to access the data in the cleaned SQL table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select in SQL and read result to pandas DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 14.4122209549 seconds ---\n",
      "--- 15.6923959255 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "# set query string\n",
    "sql_query = \"\"\"\n",
    "SELECT \n",
    "    id,longitude,latitude,title,tags,dateupload,datetaken,title_tags \n",
    "FROM \n",
    "    flickr_all \n",
    "WHERE \n",
    "    title_tags ~ 'dog';\n",
    "\"\"\"\n",
    "# Run query and save in DF\n",
    "dog_all_clean = pd.read_sql_query(sql_query,conn)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -> 14.4 seconds. And it doesn't really matter how many columns I return."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read everything to pandas and select on DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 66.9651710987 seconds ---\n",
      "--- 5.4604640007 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# set query string\n",
    "sql_query = \"\"\"\n",
    "SELECT \n",
    "    id,longitude,latitude,title,tags,dateupload,datetaken,title_tags \n",
    "FROM \n",
    "    flickr_all \n",
    "\"\"\"\n",
    "# Run query and save in DF\n",
    "flickr_all_clean = pd.read_sql_query(sql_query,conn)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "start_time = time.time()\n",
    "flickr_all_clean_dogs = flickr_all_clean[flickr_all_clean['title_tags'].str.contains(\"dog\", na=False)]\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -> ~70 seconds. \n",
    "### But: Most of this comes from reading into the DF. \n",
    "### Selecting the matching rows only takes ~5 seconds. \n",
    "### Solution: read table to DF initially upon starting the webiste and keep DF in memory for selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Close connection to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Close communication with the database\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# More commands for interacting with the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rollback transaction that created errors\n",
    "conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Delete entire table from db\n",
    "cur.execute(\"DROP TABLE flickr_tmp;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And commit the deletion\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
